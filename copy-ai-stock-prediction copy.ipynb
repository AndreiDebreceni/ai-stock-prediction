{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We bring the imports we need"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "from datetime import datetime\n",
    "import yfinance as yf\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split\n",
    "import tensorflow as tf\n",
    "from keras.models import Sequential\n",
    "from keras.layers import LSTM, Dense, GRU, SimpleRNN, Dropout\n",
    "from keras.optimizers import Adam\n",
    "from keras.callbacks import LearningRateScheduler\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Load dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will use yfincance to get the data from *Microsoft*"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "end = datetime.now()\n",
    "start = datetime(2019, end.month, end.day)\n",
    "dataset = yf.download(\"MSFT\", start, end)\n",
    "dataset.shape\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Inspect dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's see the dataset that we have"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.tail()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we remove the last row and we save it in a new variable to use it to compare predicted price with the last price we have in the last row."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "actual_close = dataset.iloc[-1]['Close']\n",
    "dataset.drop(dataset.index[-1], inplace=True)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for null data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.isna().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will check what type of data are the columns from dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's check for duplicates"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset.duplicated().sum()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's observe the dataset in a plot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "palette = sns.color_palette(\"husl\", 5)\n",
    "sns.lineplot(data=dataset[['Open', 'High', 'Low', 'Close', 'Adj Close']],palette=palette) \n",
    "plt.title('Stock Price')\n",
    "plt.xlabel('Time [Days]')\n",
    "plt.ylabel('Price')\n",
    "plt.legend(labels=['Open', 'High', 'Low', 'Close', 'Adj Close'], loc='best')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "original_dataset = dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transform the data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We normalize the data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# scaler = MinMaxScaler()\n",
    "# columns_to_normalize = ['Open', 'High', 'Low', 'Adj Close', 'Volume']\n",
    "# dataset[columns_to_normalize] = scaler.fit_transform(dataset[columns_to_normalize])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "scaler = MinMaxScaler(feature_range=(0, 1))\n",
    "scaled_data = scaler.fit_transform(dataset['Close'].values.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Splitting the data\n",
    "X_train, y_train: Training set, used to train your model.\n",
    "X_val, y_val: Validation set, used to evaluate model performance during training.\n",
    "X_test, y_test: Test set, used to evaluate the final performance of your trained model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# X = dataset[['Open', 'High', 'Low', 'Adj Close']]\n",
    "# y = dataset[['Close']]\n",
    "# X_train, X_val_test, y_train, y_val_test = train_test_split(X, y, test_size=0.2, shuffle=False)\n",
    "# X_val, X_test, y_val, y_test = train_test_split(X_val_test, y_val_test, test_size=0.5, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We sets the number of time steps to 10, meaning each sequence will contain 10 data points.\n",
    "X_train_seq, y_train_seq = create_time_steps(X_train, time_steps): This creates sequences for the training data (X_train_seq contains input sequences, and y_train_seq contains corresponding labels).\n",
    "X_val_seq, y_val_seq = create_time_steps(X_val, time_steps): This creates sequences for the validation data.\n",
    "X_test_seq, y_test_seq = create_time_steps(X_test, time_steps): This creates sequences for the test data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_sequences(data, seq_length):\n",
    "    X, y = [], []\n",
    "    for i in range(len(data)-seq_length):\n",
    "        X.append(data[i:i+seq_length])\n",
    "        y.append(data[i+seq_length])\n",
    "    return np.array(X), np.array(y)\n",
    "\n",
    "# Create sequences with a length of 10 (you can adjust this)\n",
    "sequence_length = 10\n",
    "X, y = create_sequences(scaled_data, sequence_length)\n",
    "\n",
    "# Split data into training and testing sets\n",
    "train_size = int(len(X) * 0.8)\n",
    "test_size = len(X) - train_size\n",
    "X_train, X_test = X[:train_size], X[train_size:]\n",
    "y_train, y_test = y[:train_size], y[train_size:]\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Learning rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_lr_scheduler(initial_lr, decay_factor, decay_epochs):\n",
    "    def lr_scheduler(epoch, lr):\n",
    "        if epoch % decay_epochs == 0 and epoch != 0:\n",
    "            lr = lr * decay_factor\n",
    "        return lr\n",
    "    return LearningRateScheduler(lr_scheduler)\n",
    "\n",
    "# Example usage:\n",
    "lr_callback = create_lr_scheduler(initial_lr=0.001, decay_factor=0.9, decay_epochs=15)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "global_lr_callback = create_lr_scheduler(initial_lr=0.001, decay_factor=0.9, decay_epochs=20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create Model RNN Sequential LSTM"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We create a sequential model using an LSTM layer followed by a Dense output layer\n",
    "we are predicting the future value of the 'Close' price of a stock based on past values of the 'Open', 'High', 'Low', and 'Adj Close' prices.\n",
    "\n",
    "Input: Each input sequence consists of past values of 'Open', 'High', 'Low', and 'Adj Close' prices, represented as a sequence of 10 time steps.\n",
    "Output: The model is trained to predict the next value of the 'Close' price following the input sequence."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential([\n",
    "    LSTM(units=128, activation='relu', input_shape=(sequence_length, 1)),\n",
    "    Dense(units=1)\n",
    "\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define the optimizer and compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We train the model :\n",
    "X_train_seq: This is the input data that we use to train your model. Here X_train_seq contains sequences of past values of 'Open', 'High', 'Low', and 'Adj Close' prices, and each sequence has a length of 10 time steps.\n",
    "y_train_seq: This is the target data that we try to predict during training. In this case, y_train_seq contains the next value of the 'Close' price corresponding to each sequence in X_train_seq."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "model.fit(X_train, y_train, batch_size=32, epochs=100, callbacks=[global_lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_loss = model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Training Loss: {train_loss}')\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Inverse transform the predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "train_predict = model.predict(X_train)\n",
    "test_predict = model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "train_predict = scaler.inverse_transform(train_predict)\n",
    "test_predict = scaler.inverse_transform(test_predict)\n",
    "\n",
    "# Inverse transform the actual values\n",
    "y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We plot the prediction and the initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "#plt.plot(dataset.index[:len(y_train_inv)], y_train_inv, label='Actual (Training)')\n",
    "plt.plot(dataset.index[len(y_train_inv):len(y_train_inv)+len(y_test_inv)], y_test_inv, label='Actual (Testing)')\n",
    "#plt.plot(dataset.index[:len(train_predict)], train_predict, label='Predicted (Training)')\n",
    "plt.plot(dataset.index[len(y_train_inv):len(y_train_inv)+len(test_predict)], test_predict, label='Predicted (Testing)')\n",
    "plt.title('Microsoft Stock Price Prediction using LSTM')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## GRU model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We will create a GRU model to see how it will perform"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "gru_model = Sequential([\n",
    "    GRU(units=128, activation='relu', input_shape=(sequence_length, 1)),\n",
    "    Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Define optimizer and compile the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Model training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "gru_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "gru_model.fit(X_train, y_train, batch_size=32, epochs=100, callbacks=[global_lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_loss = gru_model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = gru_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Training Loss: {train_loss}')\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Scale the data to initial state"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "gru_train_predict = gru_model.predict(X_train)\n",
    "gru_test_predict = gru_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "gru_train_predict = scaler.inverse_transform(gru_train_predict)\n",
    "gru_test_predict = scaler.inverse_transform(gru_test_predict)\n",
    "\n",
    "# Inverse transform the actual values\n",
    "y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Plot the prediction and the initial data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "#plt.plot(dataset.index[:len(y_train_inv)], y_train_inv, label='Actual (Training)')\n",
    "plt.plot(dataset.index[len(y_train_inv):len(y_train_inv)+len(y_test_inv)], y_test_inv, label='Actual (Testing)')\n",
    "#plt.plot(dataset.index[:len(train_predict)], train_predict, label='Predicted (Training)')\n",
    "plt.plot(dataset.index[len(y_train_inv):len(y_train_inv)+len(gru_test_predict)], gru_test_predict, label='Predicted (Testing)')\n",
    "plt.title('Microsoft Stock Price Prediction using GRU')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Actual price from today compared with both models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_predicted_close_lstm = test_predict[-1][0]\n",
    "last_predicted_close_gru = gru_test_predict[-1][0]\n",
    "\n",
    "print(\"Actual price: \", actual_close)\n",
    "print(\"LSTM Prediction: \", last_predicted_close_lstm)\n",
    "print(\"GRU Prediction\", last_predicted_close_gru)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## RNN Simple model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "rnn_model = Sequential([\n",
    "    SimpleRNN(units=128, activation='relu', input_shape=(sequence_length, 1)),\n",
    "    Dense(units=1)\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model\n",
    "rnn_model.compile(optimizer='adam', loss='mean_squared_error')\n",
    "\n",
    "# Train the model\n",
    "rnn_model.fit(X_train, y_train, batch_size=32, epochs=100, callbacks=[global_lr_callback])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluate the model\n",
    "train_loss = rnn_model.evaluate(X_train, y_train, verbose=0)\n",
    "test_loss = rnn_model.evaluate(X_test, y_test, verbose=0)\n",
    "\n",
    "print(f'Training Loss: {train_loss}')\n",
    "print(f'Test Loss: {test_loss}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predictions\n",
    "rnn_train_predict = rnn_model.predict(X_train)\n",
    "rnn_test_predict = rnn_model.predict(X_test)\n",
    "\n",
    "# Inverse transform the predictions\n",
    "rnn_train_predict = scaler.inverse_transform(rnn_train_predict)\n",
    "rnn_test_predict = scaler.inverse_transform(rnn_test_predict)\n",
    "\n",
    "# Inverse transform the actual values\n",
    "y_train_inv = scaler.inverse_transform(y_train.reshape(-1, 1))\n",
    "y_test_inv = scaler.inverse_transform(y_test.reshape(-1, 1))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Plotting\n",
    "plt.figure(figsize=(14, 7))\n",
    "#plt.plot(dataset.index[:len(y_train_inv)], y_train_inv, label='Actual (Training)')\n",
    "plt.plot(dataset.index[len(y_train_inv):len(y_train_inv)+len(y_test_inv)], y_test_inv, label='Actual (Testing)')\n",
    "#plt.plot(dataset.index[:len(train_predict)], train_predict, label='Predicted (Training)')\n",
    "plt.plot(dataset.index[len(y_train_inv):len(y_train_inv)+len(rnn_test_predict)], rnn_test_predict, label='Predicted (Testing)')\n",
    "plt.title('Microsoft Stock Price Prediction using RNN Simple')\n",
    "plt.xlabel('Date')\n",
    "plt.ylabel('Stock Price')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "last_predicted_close_lstm = test_predict[-1][0]\n",
    "last_predicted_close_gru = gru_test_predict[-1][0]\n",
    "last_predicted_close_rnn = rnn_test_predict[-1][0]\n",
    "\n",
    "print(\"Actual price: \", actual_close)\n",
    "print(\"LSTM Prediction: \", last_predicted_close_lstm)\n",
    "print(\"GRU Prediction: \", last_predicted_close_gru)\n",
    "print(\"RNN Prediction: \", last_predicted_close_rnn)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# To predict for the next 10 days, you'll need the last n_past days of data\n",
    "last_sequence = X_test[-1]\n",
    "\n",
    "# Reshape the last_sequence to match the input shape of the model\n",
    "last_sequence = last_sequence.reshape(1, sequence_length, 1)\n",
    "\n",
    "# Generate predictions for the next 10 days\n",
    "predictions_next_10_days = []\n",
    "for _ in range(10):\n",
    "    next_day_prediction = model.predict(last_sequence, verbose=0)\n",
    "    predictions_next_10_days.append(next_day_prediction[0, 0])  # Get the predicted value\n",
    "    last_sequence = np.roll(last_sequence, -1, axis=1)  # Shift the sequence by one day\n",
    "    last_sequence[0, -1, 0] = next_day_prediction  # Update the last element with the new prediction\n",
    "\n",
    "# Transform the predictions back to the original scale\n",
    "predictions_next_10_days = scaler.inverse_transform(np.array(predictions_next_10_days).reshape(-1, 1))\n",
    "\n",
    "# Print the predictions for the next 10 days\n",
    "print(\"Predictions for the next 10 days:\")\n",
    "for i, prediction in enumerate(predictions_next_10_days, start=1):\n",
    "    print(f\"Day {i}: Predicted Price = {prediction[0]}\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "stock-prediction-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.18"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
